\documentclass[12pt]{article}

\usepackage{graphicx}
\graphicspath{{plots/}}
\usepackage{afterpage}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{bm}
\usepackage{epsfig}
\usepackage{rotating}
\usepackage{setspace}
\usepackage{tabls}
\usepackage{hhline}
\usepackage{float}
\usepackage{subfigure}
\usepackage{subfigmat}
%\usepackage{citesort}
%\usepackage{cites}
%\usepackage{overcite}                                                                                                            
% uncomment for submission of manuscript to NSE
%\usepackage[nolists, nomarkers]{endfloat}
%
% use to include postscript figures

%
%\usepackage[light,firsttwo]{draftcopy}
%\draftcopySetGrey{0.90}
                                                                                                            
%\usepackage{dbl}

\usepackage{diagbox}
% -----------------------------------------------------------------------------
% define newcommands
% -----------------------------------------------------------------------------

%\setlength{\floatsep}{4pt plus 1pt minus 1pt}
\setlength{\textfloatsep}{8pt plus 1pt minus 1pt}
%\setlength{\intextsep}{4pt plus 1pt minus 1pt}
\setlength{\abovedisplayskip}{4pt plus 1pt minus 1pt}
\setlength{\belowdisplayskip}{4pt plus 1pt minus 1pt}

\makeatletter
%\renewcommand{\@thesubfigure}{\thefigure\thesubfigure\space}
\makeatother
% =================================================================================================
% more new commands
% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8.5in}
\setlength{\oddsidemargin}{0in}
\setlength{\topmargin}{0pt}
\setlength{\headsep}{12pt}
%\addtolength{\oddsidemargin}{-0.5in}
%\addtolength{\textwidth}{1.0in}
%\addtolength{\textheight}{1.0in}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
%
% -----------------------------------------------------------------------------
% define newcommands
% -----------------------------------------------------------------------------

%\setlength{\floatsep}{4pt plus 1pt minus 1pt}
\setlength{\textfloatsep}{8pt plus 1pt minus 1pt}
%\setlength{\intextsep}{4pt plus 1pt minus 1pt}
\setlength{\abovedisplayskip}{4pt plus 1pt minus 1pt}
\setlength{\belowdisplayskip}{4pt plus 1pt minus 1pt}

% =================================================================================================
% more new commands
% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

% Ways of grouping things
%
\newcommand{\bracket}[1]{\left[ #1 \right]}
\newcommand{\bracet}[1]{\left\{ #1 \right\}}
\newcommand{\fn}[1]{\left( #1 \right)}
\newcommand{\ave}[1]{\left\langle #1 \right\rangle}
%
% Derivative forms
%
\newcommand{\dx}[1]{\,d#1}
\newcommand{\dxdy}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dxdt}[1]{\frac{\partial #1}{\partial t}}
\newcommand{\dxdz}[1]{\frac{\partial #1}{\partial z}}
\newcommand{\dfdt}[1]{\frac{\partial}{\partial t} \fn{#1}}
\newcommand{\dfdz}[1]{\frac{\partial}{\partial z} \fn{#1}}
\newcommand{\ddt}[1]{\frac{\partial}{\partial t} #1}
\newcommand{\ddz}[1]{\frac{\partial}{\partial z} #1}
\newcommand{\dd}[2]{\frac{\partial}{\partial #1} #2}
\newcommand{\ddx}[1]{\frac{\partial}{\partial x} #1}
\newcommand{\ddy}[1]{\frac{\partial}{\partial y} #1}
%
% Vector forms
%
%\renewcommand{\vec}[1]{\ensuremath{\stackrel{\rightarrow}{#1}}}
%\renewcommand{\div}{\ensuremath{\vec{\nabla} \cdot}}
%\newcommand{\grad}{\ensuremath{\vec{\nabla}}}
\renewcommand{\vec}[1]{\overrightarrow{#1}}
\renewcommand{\div}{\vec{\nabla}\! \cdot \!}
\newcommand{\grad}{\vec{\nabla}}
\newcommand{\oa}[1]{\fn{\frac{1}{3}\hat{\Omega}\!\cdot\!\overrightarrow{A_{#1}}}}

%
% Equation beginnings and endings
%
\newcommand{\bea}{\begin{eqnarray}}
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\beas}{\begin{eqnarray*}}
\newcommand{\eeas}{\end{eqnarray*}}
\newcommand{\bdm}{\begin{displaymath}}
\newcommand{\edm}{\end{displaymath}}
%
% Equation punctuation
%
\newcommand{\pec}{\hspace{0.25in},}
\newcommand{\pep}{\hspace{0.25in}.}
\newcommand{\pev}{\hspace{0.25in}}
%
% Equation labels and references, figure references, table references
%
\newcommand{\LEQ}[1]{\label{eq:#1}}
\newcommand{\EQ}[1]{Eq.~(\ref{eq:#1})}
\newcommand{\EQS}[1]{Eqs.~(\ref{eq:#1})}
\newcommand{\REQ}[1]{\ref{eq:#1}}
\newcommand{\LFI}[1]{\label{fi:#1}}
\newcommand{\FI}[1]{Fig.~\ref{fi:#1}}
\newcommand{\RFI}[1]{\ref{fi:#1}}
\newcommand{\LTA}[1]{\label{ta:#1}}
\newcommand{\TA}[1]{Table~\ref{ta:#1}}
\newcommand{\RTA}[1]{\ref{ta:#1}}

%
% List beginnings and endings
%
\newcommand{\bl}{\bss\begin{itemize}}
\newcommand{\el}{\vspace{-.5\baselineskip}\end{itemize}\ess}
\newcommand{\ben}{\bss\begin{enumerate}}
\newcommand{\een}{\vspace{-.5\baselineskip}\end{enumerate}\ess}
%
% Figure and table beginnings and endings
%
\newcommand{\bfg}{\begin{figure}}
\newcommand{\efg}{\end{figure}}
\newcommand{\bt}{\begin{table}}
\newcommand{\et}{\end{table}}
%
% Tabular and center beginnings and endings
%
\newcommand{\bc}{\begin{center}}
\newcommand{\ec}{\end{center}}
\newcommand{\btb}{\begin{center}\begin{tabular}}
\newcommand{\etb}{\end{tabular}\end{center}}
%
% Single space command
%
%\newcommand{\bss}{\begin{singlespace}}
%\newcommand{\ess}{\end{singlespace}}
\newcommand{\bss}{\singlespacing}
\newcommand{\ess}{\doublespacing}
%
%---New environment "arbspace". (modeled after singlespace environment
%                                in Doublespace.sty)
%   The baselinestretch only takes effect at a size change, so do one.
%
\def\arbspace#1{\def\baselinestretch{#1}\@normalsize}
\def\endarbspace{}
\newcommand{\bas}{\begin{arbspace}}
\newcommand{\eas}{\end{arbspace}}
%
% An explanation for a function
%
\newcommand{\explain}[1]{\mbox{\hspace{2em} #1}}
%
% Quick commands for symbols
%
\newcommand{\half}{\frac{1}{2}}
\newcommand{\third}{\frac{1}{3}}
\newcommand{\twothird}{\frac{2}{3}}
\newcommand{\mdot}{\dot{m}}
\newcommand{\ten}[1]{\times 10^{#1}\,}
\newcommand{\cL}{{\cal L}}
\newcommand{\cD}{{\cal D}}
\newcommand{\cF}{{\cal F}}
\newcommand{\cE}{{\cal E}}
\newcommand{\cS}{{\cal S}}
\newcommand{\mA}{\mathbf{A}}
\newcommand{\mX}{\mathbf{X}}
\newcommand{\mU}{\mathbf{U}}
\newcommand{\mW}{\mathbf{W}}
\newcommand{\mSigma}{\mathbf{\Sigma}}
\newcommand{\mS}{\mathbf{S}}
\newcommand{\mB}{\mathbf{B}}
\newcommand{\mC}{\mathbf{C}}
\newcommand{\mD}{\mathbf{D}}
\renewcommand{\Re}{\mbox{Re}}
\newcommand{\Ma}{\mbox{Ma}}
%
% Inclusion of Graphics Data
%
%\input{psfig}
%\psfiginit
%
% More Quick Commands
%
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\dxi}{\Delta x_i}
\newcommand{\dyj}{\Delta y_j}
\newcommand{\ts}[1]{\textstyle #1}
% =================================================================================================
\date{}

\begin{document}

%\bibliographystyle{nse}
%\bibnum{p}

\thispagestyle{empty}

\bss
\bc
{\Large \bf Dynamic Mode Decomposition for Subcritical Metal Systems}\\
\vspace{0.3in}
{\large Zachary Hardy and Jim E. Morel\\
Texas A\&M University\\
Department of Nuclear Engineering\\
TAMU 3133\\
College Station, TX 77843-3133\\
$ $\\
Cory Ahrens\\
Los Alamos National Laboratory\\
Los Alamos, NM  87545\\
$ $\\
}
\emph{zach.hardy@tamu.edu, morel@tamu.edu, cdahrens@lanl.gov}

\vspace{1.5in}

Send proofs and page charges to:\\
\vspace{0.1in}
Dr. Jim Morel\\
Texas A\&M University\\
Department of Nuclear Engineering\\
TAMU 3133\\
College Station, TX 77843-3133\\
\vspace{0.25in}
25 Pages -- 1 Table -- 4 Figures \\
\ec
\ess

% =================================================================================================

\newpage

\begin{abstract}
In this paper we explore the use of Dynamic Mode Decomposition (DMD) for modeling the kinetics of 
subcritical metal systems pulsed with fast neutrons.  Our ultimate purpose is to obtain a fast and 
accurate reduced-order model for such systems that can be used to develop an emulator.  
An alternative to DMD is $\alpha$-eigenfunction expansions, but we show that DMD is vastly superior in 
several ways for the systems of interest to us. 
\end{abstract}

\section{Introduction}
The modeling of subcritical metal systems subjected to short bursts of fast neutrons is of interest 
to us.  While such modeling can certainly be done with a time-dependent Sn code, we want to develop a
reduced-order model that can provide insight into such systems and form the basis of an emulator in 
order to solve inverse problems quickly and compute sensitivities economically.  For a supercritical 
system, it is clear that the transport solution will eventually be completely dominated by the 
fundamental mode $\alpha$-eigenfunction because it grows more quickly than any other mode.  However, the 
situation is quite different for a subcritical system because the fundamental mode $\alpha$-eigenfunction 
is simply the most slowly decaying mode.  There is no guarantee that it will dominate or even make a significant 
contribution to the solution before the solution is negligibly small.  Its practical importance in a solution 
depends upon the extent to which it is present in the expansion for the initial condition.  In 
a subcritical system the fundamental mode will be dominated by the slowest neutrons, which will be thermal 
neutrons. In a metal system subjected to a burst of fast neutrons, there will be almost no thermal neutrons 
created before the pulse has effectively died away.  Thus it seems likely that an $\alpha$-eigenfunction expansion 
will be particularly inefficient for such systems, because a high degree of cancellation between the eigenfunctions 
will be required to achieve a negligible thermal neutron component in the initial condition.  

Dynamic Mode Decomposition (DMD) is a reduced order technique for modeling dynamical systems.  It has been applied 
in many areas (need references) and is perhaps best known for its use in the fluid-flow community.  The purpose of 
this paper is to perform a preliminary investigation of DMD as an alternative to $\alpha$-eigenfunction expansions 
for modeling our pulsed neutron experiments. (Need to reference any previous neutronics work with DMD here.) 
For this initial study, we use a very approximate but relevant 
high-dimensional model consisting of a time-dependent 1-D spherical geometry three-group diffusion approximation. 
We have a analytic eigenfunction solution for these equations, as well as a computer code for solving 
these equations with second-order accuracy in both time and space.  We later describe DMD in detail, but at 
this point it suffices to say that given a time series of vector ``snapshots'' from a simulation or experiment, 
DMD produces a time-dependent solution for those snapshots that is constructed from a sum of snapshot modes, each with 
an exponential decay rate.  For instance, the snapshots could be space-dependent three-group diffusion scalar fluxes 
from a time-dependent calculation.  They could also be an analogous time series of any quantity of interest computed 
from the diffusion solution, such as space-dependent reaction rates.  The form of the DMD solution is identical to that 
of an alpha-eigenfunction solution.  However, the DMD modes can only contain what the snapshots contain, so if the snapshots 
lack a thermal neutron component, so will the DMD modes.  This suggests that fewer DMD modes should be required for 
our problems than $\alpha$-eigenfunctions.

Indeed we present results demonstrating that the DMD method is extremely accurate and far more efficient than 
$\alpha$-eigenfunction expansions for our problems.  The remainder of this paper is organized as follows.  First we describe 
the particular variant of the DMD method that we use.  Then we describe the three-group diffusion model, followed by a 
description of our space-time discretization for the diffusion model.  Finally, numerical results are given, followed by 
conclusions and recommendations for future work.


\section{The DMD Method}
There are many variations of the DMD method.  Here we describe the variant that we use to model subcritical fissioning systems.  
One begins with a time series of vector snapshots, $\{\vec{v}_j\}_{j=1}^{N}$, uniformly sampled in time, that are associated with the 
dynamical system.  We assume that at least the first $N-1$ snapshots are linearly-independent. A process for ensuring this 
is later discussed.  Each vector has $M$ real 
components with $M \gg N$. For example, each snapshot could represent a discrete angular flux solution in a time-dependent 
transport calculation, or it could represent some space-dependent 
quantity of interest associated with that solution.  Note that the snapshots can be obtained either computationally or 
experimentally. For our application, we generate them computationally. It is further assumed that there exists a temporal 
matrix $\mathbf{A}$, that maps each snapshot to its successor:
\be
\vec{v}_{i+1} = \mA \vec{v}_{i} \pec \quad i=1,N-1.
\LEQ{2.1}
\ee
Let us consider the subspace of $M$-vectors, which we denote by $\cS$, spanned by the first $N-1$ snapshots.  If $\vec{v}_N$ 
were replaced by a least-squares fit from $\cS$, then $\mA$ would be uniquely defined as a mapping from $\cS$ to $\cS$, and 
be represented by the following matrix with respect to the snapshot basis:
\be
\mA_s = \bracket{
\begin{array}{ccccccc}
0 & 0 & ....& 0 & c_1 \\
1 & 0 & ....& 0 & c_2 \\
0 & 1 & ....& 0 & c_3 \\
. & . & ....& . & . \\
. & . & ....& . & . \\
. & . & ....& . & . \\
0 & 0 & ....& 0 & . \\
0 & 0 & ....& 1 & c_{N-1}
\end{array}
} \pec
\LEQ{2.2}
\ee
where the least-squares fit to $\vec{v}_N$ from $\cS$ is represented by 
\be
\widehat{v}_N = \sum_{j=1}^{N-1} c_j \vec{v}_j \pep
\LEQ{2.3}
\ee
For example, in the snapshot basis, 
\be
\vec{v}_1 = (1,0,0,0,...0)^T \pec
\LEQ{2.4}
\ee
and 
\be
\mA \vec{v}_1 = \vec{v}_2 = (0,1,0,0,...0)^T \pec
\LEQ{2.5}
\ee
Note that if $c_1$ is non-zero, $\mA$ will be invertible on $\cS$, and thus will have $N-1$ non-zero eigenvalues. 
We will define $\mA$ in this manner with respect to $\cS$, assume that it is invertible on $\cS$, and further define 
all of its remaining eigenvalues to be zero.  
Let $\{\lambda_i\}_{i=1}^{N-1}$ denote the non-zero eigenvectors of $\mA$, and let $\{\vec{z}_i\}_{i=1}^{N-1}$ denote the 
corresponding eigenvectors. Then the dynamic solution is given by 
\be
\vec{v}(t) = \sum_{i=1}^{N-1} a_i \vec{z}_i \exp{(\omega_i t)} \pec
\LEQ{2.5a}
\ee
where 
\be
\omega_i = \frac{\ln{(\lambda_i)}}{\Delta t} \pec
\LEQ{2.5b}
\ee
where $\Delta t$ is the time between snapshots and the expansion coefficients, $\{a_i\}_{i=1}^{N-1}$ are determined by the 
initial condition:
\be
\vec{v}(0) = \vec{v}_1 = \sum_{i=1}^{N-1} a_i \vec{z}_i \pep
\LEQ{2.5c}
\ee
The dynamic solution exactly reproduces each of the snapshots at its time of sampling with the 
exception of the last snapshot, which is approximated with its least-squares fit. This follows from the 
fact that at the end of the first sampling period, $\mA$ is effectively applied to $\vec{v}_1$, 
and reapplied at the end of each sampling period thereafter.  For instance, 
\bea
\vec{v}(\Delta t) &=& \sum_{i=1}^{N-1} a_i \vec{z}_i \exp{(\omega_i \Delta t)} \pec \nonumber \\
&=& \sum_{i=1}^{N-1} a_i \vec{z}_i \lambda_i \pec \nonumber \\ 
&=& \mA \vec{v}_1 \pec \nonumber \\ 
&=& \vec{v}_2 \pep
\LEQ{2.5d}
\eea 
Note that any eigenfunction with a zero-eigenvalue will have no dynamic content because it will 
instantly attenuate to zero.  Thus if $\widehat{v}_N$ has a zero value for $c_1$ in \EQ{2.3},
$\mA$ will have only $N-2$ non-zero eigenvalues, and one can simply ignore the eigenfunction associated 
with the extra zero eigenvalue.  We henceforth continue to assume that $\mA$ has $N-1$ non-zero eigenvalues 
for simplicity, but without loss of generality.

We now describe a process that enables us to compute the non-zero eigenvalues and the eigenvectors of 
of $\mA$.  Furthermore, we need not explicitly compute $\widehat{v}_N$.   First we 
express \EQ{2.1} as follows, neglecting the substitution of $\widehat{v}_N$ for $\vec{v}_N$ for reasons later explained. 
\be
\mX_2^{N} = \mA \mX_{1}^{N-1} \pec
\LEQ{2.6}
\ee
where $\mX_2^{N}$ is the $M \times N-1$ matrix whose colunms are the vectors $\vec{v}_2$ through $\vec{v}_{N}$, 
and $\mX_{1}^{N-1}$ is the $M\times N-1$ matrix whose colunms are the vectors $\vec{v}_1$ through 
$\vec{v}_{N-1}$. 

We next perform a singular value decomposition (SVD) of $\mX_{1}^{N-1}$:
\be
\mX_{1}^{N-1} = \mU \mSigma \mW^T \pec
\LEQ{2.7}
\ee
where $\mU$ is a $M \times M$ orthogonal matrix, $\mSigma$ is a $M\times N-1$ matrix with $N-1$ non-zero singular values on 
the diagonal and zeros everywhere else, and $\mW^T$ is a 
$N-1 \times N-1$ orthogonal matrix.  Substituting from \EQ{2.6} into \EQ{2.7}, we obtain, 
\be
\mX_2^{N} = \mA \mU \mSigma \mW^T \pec
\LEQ{2.8}
\ee
Next we multiply \EQ{2.8} on the left by $\mU^{T}$ 
and on the right by $\mW\mSigma^{-1}$ to obtain 
\be
\mS = \mU^{T}\mX_2^{N}\mW\mSigma^{-1} = \mU^{T}\mA\mU \pec
\LEQ{2.10}
\ee
where $\mSigma^{-1}$ is the pseudo inverse of $\mSigma$.  
The pseudo-inverse is obtained from $\mSigma$ simply by first inverting its non-zero elements and then transposing it. 
Note that the right side of \EQ{2.10} is a $M \times M$ matrix that represents a similarity transformation 
of $\mA$, and thus $\mS$ has the same eigenvalues as $\mA$.  Furthermore, in accordance with the similarity transformation, 
if $\vec{y}$ is an eigenvector of $\mS$, then $\vec{z} = \mU \vec{y}$ is an eigenvector of $\mA$.  

The structure of $\mS$ is important because it enables us to avoid computing the entire $M \times M$ matrix together with 
its eigenvalues and eigenvectors.  More specifically, all the columns of $\mS$ beyond column $N-1$ are zero, and 
we represent the remainder of the matrix as an $N-1 \times N-1$ matrix, $\mS_{T}$, in the upper top left corner and 
a $M-N+1 \times N-1$ matrix, $\mS_B$, in the bottom left corner:
\be
\mS = \bracket{
\begin{array}{cc}
\mS_T  & 0 \\
\mS_B & 0  
\end{array}
} \pec
\LEQ{2.11}
\ee
It can be shown that the eigenvalues of $\mS_T$ are the non-zero eigenvalues of $\mS$, and hence, the non-zero eigenvalues of 
$\mA$.  Furthermore, there is a very simple way to compute the corresponding eigenvectors of $\mS$ from the eigenvectors of 
$\mS_T$. However, it is unnecessary to compute any eigenvectors other than those of $\mS_T$.  To explain why this is so, we 
first note that the there is no difference between the eigenvectors of $\mS_T$ and the vectors formed by the first $N-1$ 
components of the corresponding eigenvectors of $\mS$.  Thus if one computes the eigenvalues and eigenvectors of $\mS_T$, 
one has the non-zero eigenvalues of $\mA$ and $\mS$, and the corresponding eigenvectors of $\mS$ truncated to a length of $N-1$.

The first step in the calculation of the non-zero eigenvalues and corresponding eigenvectors of $\mA$ is to directly 
compute $\mS_T$ as follows:
\be
\mS_T = \mU_{N-1}^{T} \mX_{2}^{N}\mW\mSigma^{-1}_{N-1} \pec
\LEQ{2.12}
\ee
where $\mU_{N-1}$ is the $M \times N-1$ matrix composed of the first $N-1$ columns of $\mU$, and $\mSigma_{N-1}$ is the 
$N-1 \times N-1$ matrix formed by the first $N-1$ rows of $\mSigma$.  

At this point we have sufficient information to explain why one need not substitute $\widehat{v}_N$ for $\vec{v}_N$ in 
$\mX_2^{N}$.  To this end we express the equations for the expansion coefficients of the least-squares fit to $\vec{v}_N$ 
as follows:
\be
\mU^T_{N-1}\fn{\widehat{v}_N - \vec{v}_N} = \vec{0} \pec
\LEQ{2.9}
\ee
where $\mU_{N-1}$ is the $M \times N-1$ matrix consisting of the first $N-1$ columns of $\mU$. Note that by virtue of the 
SVD of $\mX_{1}^{N-1}$, these column vectors represent an orthonormal basis for the first $N-1$ snapshots.  Thus $\widehat{v}_N$ 
does indeed represent a least-squares fit to $\vec{v}_N$ from $\cS$.  From \EQ{2.9} it follows that the first $N-1$ components of 
$\mU^T \vec{v}_N$ are identical to those of $\mU^T \widehat{v}_N$. Thus it can be seen from \EQ{2.12} that $\mS_T$ is 
invariant to the substitution of $\widehat{v}_N$ for $\vec{v}_N$ in $X_{2}^{N}$.

Finally, we compute the non-zero eigenvectors of $\mA$ simply by multiplying the eigenvectors of $\mS_T$ by $U_{N-1}$. 
\be
\vec{z}_i = \mU_{N-1} \vec{x}_i \pec \quad i=1,N-1,
\LEQ{2.13}
\ee
where $\vec{z}_i$ and $\vec{x}_i$ are the $i$'th eigenvectors of $\mA$ and $\mS_T$, respectively.  This is clearly much more 
economical than computing the eigenvectors of $\mS$ and multiplying them by $\mU$.  This simplification is justified by the fact 
that since the first $N-1$ columns of $\mU$ form an orthonormal basis for $\cS$, the non-zero eigenvectors of $\mA$ 
must lie in this space.  Thus columns of $\mU$ beyond $N-1$, or equivalently, elements of the eigenvectors of $\mS$ below the 
$N-1$ position do not contribute to the non-zero eigenvectors of $\mA$. 

The SVD of $\mX_{1}^{N-1}$ can be used to determine if the first $N-1$ snapshots are sufficiently linearly independent by 
inspection of the singular values.  Below some tolerance one can consider the singular values to be zero, and discard the 
corresponding information in the various component matrices.  More specifically, if we assume that only the first $K$ 
singular values are considered non-zero, then in \EQ{2.12} only the first $K$ columns of $\mU_{N-1}$ and $\mX_{2}^{N}$ are retained, 
and only the first $K$ columns and first $K$ rows of $\mSigma_{N-1}$ and $\mW^T$ are retained.  We currently set any singular 
value that is less than $10^{-8}$ times the largest singular value to zero. It is not generally clear as to what tolerance is 
the most efficient.  We determine this on a case-by-case basis.

\section{The Three-Group Diffusion Model}
The primary goal of this work is to explore the ability of DMD to effectively filter out irrelevant portions of phase space to produce a reduced order model.  Because thermal neutrons have effectively no contribution to the results of a computational model or experiment within the application space of interest, we choose the model to reflect these characteristics. For the purposes of this  work, only diffusion in a bare, homogeneous fissioning sphere with an atom density of $N = 0.05 \text{ atoms/cc}$ is considered. 

For simplicity, and to give a clear DMD performance metric, three energy groups - fast, epithermal, and thermal - are used.  The nuclear data is tabulated in \TA{xs_data}, where $\chi$ is the fission spectrum, $\nu\sigma_f$ is the fission neutron production cross section, $\sigma_R$ is the removal cross section, including exlusively absorption and outscattering, $\sigma_t$ is the total cross section, and $v$ is the velocity.  As is apparent from the table, fission neutrons are only born into the fast group indicating that the only production of epithermal and thermal neutrons comes from downscattering. The scattering matrix is shown in \TA{scat}.  There is only scattering from the fast to epithermal group and no upscattering whatsoever.  

With this model it is assured that thermal neutrons only appear in the problem if they exist in the initial condition.  This makes the analysis of the performance of the DMD quite simple; in a problem where thermal neutrons are, in fact, irrelevant to the solution, the DMD solution should not have a thermal component. 

\bt[h] \centering 
	\caption{Nuclear data for the three-group model.} 
	\btb{|c|c|c|c|}
		\hline
		\diagbox{Reaction}{Group} & Fast  & Epithermal  & Thermal  \\  \hline
		$\chi$  & 1 & 0 & 0 \\ 	\hline
		$\nu\sigma_f \ [b]$ & 5.4 & 60.8 & 28.0 \\  \hline
		$\sigma_R \ [b]$  & 3.31 & 36.2 & 13.6 \\  \hline
		$\sigma_t \ [b]$ & 7.71 & 50.0 & 25.6\\ \hline
		$v \ [cm/\mu s]$ & 2000 & 100 & 2.2 \\  \hline
	\etb  \LTA{xs_data}
\et

\bt[h] \centering 
	\caption{Scattering matrix given in barns.} 
	\btb{|c|c|c|c|}
		\hline
		\diagbox{From}{To}& Fast  & Epithermal  & Thermal  \\  \hline
		Fast  & 0 & 1.46 & 0 \\  \hline
		Epithermal & 0 & 0 & 0 \\  \hline
		Thermal  & 0 & 0 & 0 \\  \hline
	\etb \LTA{scat}
\et

This problem is particularly advantageous because an analytical solution can be developed for the desired $\alpha$-eigenfunctions which characterize the dynamic behavior of the system. 
This system is governed by the time-dependent multi-group neutron diffusion equations. The center of the spherical system is reflective and a zero-flux condition is imposed at the physical boundary. The initial condition will be parabolic in space for both the fast and epithermal groups and zero for the thermal group. This is given in \EQ{mg_diff}.

\be
	\begin{cases}
	\dxdy{\phi_g}{t} - \nabla \cdot D_g \nabla \phi_g + \Sigma_{R,g} \phi_g = \chi_g \sum\limits_{g'=1}^{3} \nu\Sigma_{f,g'} \phi_{g'} + \sum\limits_{g'=1, \ g' \neq g}^g \Sigma_s^{g' \rightarrow g} \phi_{g'} \\
	%
	-D_g \dxdy{\phi_g}{r} \Big\rvert_{(0,t)} = 0, \pev \phi_g(R,t) = 0 \\
	%
	\phi_1(r,0) = \phi_2(r,0) = \frac{R^2 - r^2}{R^2}, \pev \phi_3(r,0) = 0
	\end{cases} 
\LEQ{mg_diff} \ee 
where $\Sigma$s are macroscopic cross sections, given by $\Sigma = N\sigma$, and $D_g$ is the diffusion coefficient, given by $1/3\Sigma_t$. This can be simplified based on the nuclear data to \EQ{simp_diff}.

\be
	\begin{cases}
	\dxdy{\phi_g}{t} - \nabla \cdot D_g \nabla \phi_g + \Sigma_{R,g} \phi_g = \chi_1 \sum\limits_{g'=1}^{3} \nu\Sigma_{f,g'} \phi_{g'} + \Sigma_s^{1 \rightarrow 2} \phi_{1} \\
	%
	-D_g \dxdy{\phi_g}{r} \Big\rvert_{(0,t)} = 0, \pev \phi_g(R,t) = 0 \\
	%
	\phi_1(r,0) = \phi_2(r,0) = \frac{R^2 - r^2}{R^2}, \pev \phi_3(r,0) = 0.
	\end{cases} 
\LEQ{simp_diff}\ee

This problem can be solved using an doubly-indexed $\alpha$-eigenfunction expansion.  The expansion takes the form shown in \EQ{exp}.

\be
	\phi_g(r, t) = \sum_{n, m = 0}^{\infty, 3} A_{nm} \varphi_n(r) f_{nm, g} e^{\alpha_{nm} t},
\LEQ{exp} \ee
where $n$ gives the index of the spatial mode and $m$ gives the index of the energy modes corresponding to each spatial mode, $A_{nm}$ is the coeffient for the $n,m$'th space-energy mode, $\varphi_n(r)$ is the $n$'th spatial mode, $f_{nm, g}$ is the $g$'th component of the $n,m$'th space-energy mode, and $\alpha_{nm}$ is the time eigenvalue for the $n,m$'th space-energy mode. The spatial modes are those of the Laplace equation for a spherical geometry given by \EQ{eigfunc}, with the same boundary conditions as those in the governing equation.

\be
	\varphi_n(r) = \frac{1}{r} \sin\fn{ \frac{n \pi r}{R} }
\LEQ{eigfunc} \ee

For simplicity, the buckling approximation is used in place of the Laplacian, as shown in \EQ{buckle}

\bea \begin{aligned}
	- \nabla^2 \varphi_n(r) &= B_n^2 \varphi_n(r) \\
	B_n^2 &= \fn{ \frac{n \pi}{R} }^2
\end{aligned} \LEQ{buckle} \eea
Plugging in the eigenfunction expansion into the governing equation, rearranging, and taking advantage of the orthogonality of the spatial eigenfunctions, an eigenvalue problem is formed for each spatial mode, given by \EQ{eigprob}.

\be
	\alpha_{nm} f_{nm, g} = v_g \fn{ - \fn{ D_g B_n^2 + \Sigma_{R,g} }f_{nm, g} + \chi_1 \sum_{g' = 1}^{3} \nu\Sigma_{f,g'} f_{nm, g'} + \Sigma_s^{1 \rightarrow 2} f_{nm, 1} } 
\LEQ{eigprob} \ee
It should be clear that this forms a 3 $\times$ 3 system which will yield 3 distinctive $\alpha$-eigenvalues with corresponding eigenvectors of length 3 for each spatial mode used in the expansion.

The coefficients for each space-energy mode is computed by a projection of the the initial condition onto each respective space-energy mode. Because the eigenproblem described above is not symmetric, the adjoint (left) eigenfunctions given by, $f_{nm}^* \varphi_n(r)$, must be used. The spatial eigenfunctions do not have the adjoint designation because they are self-adjoint. The coefficients are computed according to \EQ{coeff}.

\be
	A_{nm} = \frac{\ave{ f_{nm}^* \varphi_n(r), \ \phi(r, 0)}}{\ave{f_{nm}^* \varphi_n(r), \ f_{nm} \varphi_n(r)}},
\LEQ{coeff} \ee
where $\ave{\cdot}$ designates the inner product, an integration and sum, over space and energy, respectively. To generate the full analytic solution modes are generated and added to the solution until the $L^2$-fit to the initial condition changes by less than a specified tolerance. This expansion is then propegated forward in time with the $\alpha$-eigenfunctions to some specified  time.

\section{Discretization of the Diffusion Equations}
In practice,  $\alpha$-eigenvalue calculations for this application are quite computationally expensive, and  further, in most cases, analytic solutions is not available. For this reason, it is desireable to develop a numerical method so that the accuracy of DMD can be characterized in a realistic way and compared against a known solution. This section outlines the development of a second-order accurate method using cell-centered finite volume discretization in space and trapezoidal second-order backwards difference (TBDF-2) discretization in time.

In the spatial discretization, the domain is broken into $N$ cells, with cell width $h$, where the cell centers carry integer indiced and the edges half-integer indices. Consider \EQ{cell_eqn}, the conservation equation for the i$^{\text{th}}$ cell

\be
	 \frac{1}{v_g} \dxdt{\phi_{i,g}} - \nabla D_{g} \nabla \phi_{i,g} + \Sigma_{R,g} \phi_{i,g}  =  S_{i,g},
\LEQ{cell_eqn} \ee
where $S_{i,g}$ contains the production terms for group $g$ neutrons in cell $i$. The reader should note that source term includes the unknown $ \phi_{i,g} $ variables. Integrating over the cell volume, the following is obtained,

\be
	\frac{V_i}{v_g} \dxdt{\phi_{i,g}} - A_{i+\half} J_{i+\half,g} + A_{i-\half} J_{i-\half,g} + V_i \Sigma_{R,g} \phi_{i,g} = V_i S_{i,g}
\ee
where $V_i $ is the volume of cell $i$, $ A_{i+1/2} $ is the surface area of the outer edge of cell $i$ and $ J_{i+1/2} = D_g \nabla \phi_{g,i} $ is the current at outer edge of cell $i$. Central difference is now applied to the current terms to obtain \EQ{space_discretized}

\be
	\frac{V_i}{v_g} \dxdt{\phi_{i,g}} - A_{i+\half} \frac{\phi_{i+1,g} - \phi_{i,g}}{h} + A_{i-\half} \frac{\phi_{i,g} - \phi_{i-1,g}}{h} + V_i \Sigma_{R,g} \phi_{i,g} = V_i S_{i,g},
 \LEQ{space_discretized} \ee
 which is second-order accurate.

The TBDF-2 temporal discretization is advantageous because it is second-order accurate and strongly damps fast time-scale components of the solution unlike methods such as Crank-Nicholson, which can be highly oscillatory for stiff systems. This method first takes half of a time-step using Crank-Nicholson. This is shown for an arbitrary linear system in \EQ{halfCN}. 

\be
	\frac{2 \fn{ f^{n+\half} - f^n }}{\Delta t} =  \half A \fn{f^{n+\half} + f^n}.
\LEQ{halfCN} \ee
The result of solving for $f^{n+\half}$ is then plugged into second-order backwards difference to obtain the solution at the end of the time step, shown in \EQ{halfBDF}.

\be
	\frac{3 \fn{ f^{n+1} - f^{n+\half} }}{\Delta t} - \frac{f^{n+\half} - f^n}{\Delta t} = A f^{n+1}.
\LEQ{halfBDF} \ee 
Implementing this is relatively straightforward. The time derivative term containing the scalar flux at ther next half-time step gets added into the operator and the terms containing the scalar flux from previous time-steps become a source term.

Overall, this method is second order accurate. This was verified by computing the relative $L^2$-error norms with the analytical solution for 6-space/time grid halvings, as seen in \FI{2ord}

\bfg[h] \centering
	\includegraphics[scale=0.5]{method_convergence.png}
	\caption{Convergence of the numerical solution to the analytical}
	\LFI{2ord}
\efg



\section{Numerical Results}

\section{Conclusions and Recommendations for Future Work}

%\begin{thebibliography}{99}

%\end{thebibliography}

\end{document} 

